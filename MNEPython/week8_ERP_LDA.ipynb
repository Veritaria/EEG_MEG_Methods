{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os, mne, socket\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Get the hostname\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "if 'hpc' in hostname:\n",
    "    # You are running your code on HPC\n",
    "    curr_dir = os.getcwd()\n",
    "    path_parts = curr_dir.split(os.sep)\n",
    "    dataPath = os.path.join(os.sep, 'scratch', 'work', 'courses', 'PSYCH-GA-3405-2024fa')\n",
    "elif hostname == 'sebastian_mac':\n",
    "    # You are Sebastian\n",
    "    # Setting up paths for data\n",
    "    mydir = os.getcwd()\n",
    "    path_parts = mydir.split(os.sep)\n",
    "    idcs = [i for i, c in enumerate(mydir) if c == os.sep]\n",
    "    dataPath = mydir[:idcs[-2]]\n",
    "else:\n",
    "    # You are running on your device with Google drive path\n",
    "    # Define the paths and initialize Fieldtrip\n",
    "    my_user_id = 'mdd9787'  # change this to your netID\n",
    "    curr_dir = os.getcwd()\n",
    "    path_parts = curr_dir.split(os.sep)\n",
    "    base_dir = os.path.join(os.sep, *path_parts[:3])\n",
    "    dataPath = os.path.join(base_dir, 'Library', 'CloudStorage', f'GoogleDrive-{my_user_id}@nyu.edu', 'My Drive', 'Coursework', 'EEG MEG methods', 'ClassData')\n",
    "\n",
    "eegRoot = os.path.join(dataPath, 'EEGBids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/mrugankdake/Library/CloudStorage/GoogleDrive-mdd9787@nyu.edu/My Drive/Coursework/EEG MEG methods/ClassData/EEGBids/derivatives/mrugank/preprocessing/sub-004/sub-004_task-oddball_clean-raw.fif...\n",
      "    Range : 0 ... 2055679 =      0.000 ...  4014.998 secs\n",
      "Ready.\n",
      "Opening raw data file /Users/mrugankdake/Library/CloudStorage/GoogleDrive-mdd9787@nyu.edu/My Drive/Coursework/EEG MEG methods/ClassData/EEGBids/derivatives/mrugank/preprocessing/sub-004/sub-004_task-oddball_clean-raw-1.fif...\n",
      "    Range : 2055680 ... 2347007 =   4015.000 ...  4583.998 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "groupName = 'GroupD'  # Change group name to analyze different dataset (valid IDs: GroupA, GroupC, GroupD)\n",
    "userName = 'mrugank'  # Make sure to ensure that you are writing to your derivatives \n",
    "taskName = 'oddball'\n",
    "\n",
    "# Get subject code for your group\n",
    "groupMap = {'GroupA': '001', 'GroupC': '003', 'GroupD': '004'}\n",
    "subjCode = groupMap[groupName]\n",
    "\n",
    "dataPath = os.path.join(eegRoot, f'sub-{subjCode}', 'eeg')\n",
    "derivPath = os.path.join(eegRoot, 'derivatives', userName, 'preprocessing', f'sub-{subjCode}')\n",
    "\n",
    "if not os.path.exists(derivPath):\n",
    "    os.makedirs(derivPath)\n",
    "\n",
    "saveRoot = f'sub-{subjCode}_task-{taskName}_'\n",
    "\n",
    "# raw_clean.save(os.path.join(derivPath, f'{saveRoot}clean-raw.fif'), overwrite=True)\n",
    "# Load raw_clean\n",
    "raw_clean = mne.io.read_raw_fif(os.path.join(derivPath, f'{saveRoot}clean-raw.fif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 2347007  =      0.000 ...  4583.998 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 15 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 15.00 Hz\n",
      "- Upper transition bandwidth: 3.75 Hz (-6 dB cutoff frequency: 16.88 Hz)\n",
      "- Filter length: 451 samples (0.881 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 256 out of 256 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['/1', '/2', '/4', '/8', 'even', 'odd', 'storySeg']\n",
      "Not setting metadata\n",
      "540 matching events found\n",
      "Setting baseline interval to [-0.30078125, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "450 matching events found\n",
      "Setting baseline interval to [-0.30078125, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# ERP analysis\n",
    "# Epoch data around the semantic visual stimulus\n",
    "import numpy as np\n",
    "\n",
    "# Apply low pass filter\n",
    "raw_clean.load_data()\n",
    "raw_clean.filter(l_freq=None, h_freq=15, n_jobs=-1)\n",
    "# Convert annotations to events using these descriptions\n",
    "events, event_dict = mne.events_from_annotations(raw_clean)\n",
    "\n",
    "# Update duration in events\n",
    "for i, evtIdx in enumerate(events):\n",
    "    if evtIdx[2] not in [5, 6]:  # Skip events with code 5 or 6\n",
    "        # Check if there is any event after that is not 5 or 6\n",
    "        nextEvents = events[i+1:]\n",
    "        # Check if there are any events after the current event that are not 5 or 6\n",
    "        isNextEvent = False\n",
    "        for nextEvt in nextEvents:\n",
    "            if nextEvt[2] not in [5, 6]:\n",
    "                isNextEvent = True\n",
    "                break\n",
    "        if isNextEvent:\n",
    "            # Update duration\n",
    "            events[i, 1] = nextEvt[0] - evtIdx[0]\n",
    "        else:\n",
    "            # Update duration\n",
    "            events[i, 1] = raw_clean.times[-1] - evtIdx[0]\n",
    "\n",
    "    else:\n",
    "        # Check if there is any event after \n",
    "        nextEvents = events[i+1:]\n",
    "        if len(nextEvents) > 0:\n",
    "            events[i, 1] = nextEvents[0, 0] - evtIdx[0]\n",
    "        else:\n",
    "            events[i, 1] = raw_clean.times[-1] - evtIdx[0]\n",
    "\n",
    "semantic_vis_blocks = events[events[:, 2] == 2] # 2 is the event code for semanticVis\n",
    "semantic_aud_blocks = events[events[:, 2] == 3] # 3 is the event code for semanticAud\n",
    "\n",
    "# Filter trial events ('even' and 'odd') that occur within semanticVis blocks\n",
    "semantic_vis_events = []\n",
    "semantic_aud_events = []\n",
    "for event in events:\n",
    "    if event[2] in [int(event_dict['even']), int(event_dict['odd'])]:\n",
    "        # Check if the trial event occurs within any semanticVis block\n",
    "        for block in semantic_vis_blocks:\n",
    "            if block[0] <= event[0] <= block[0] + int(block[1]):  # Ensure event is within block duration\n",
    "                semantic_vis_events.append(event)\n",
    "                break\n",
    "\n",
    "for event in events:\n",
    "    if event[2] in [int(event_dict['even']), int(event_dict['odd'])]:\n",
    "        for block in semantic_aud_blocks:\n",
    "            if block[0] <= event[0] <= block[0] + int(block[1]):\n",
    "                semantic_aud_events.append(event)\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "# Convert to numpy array for creating epochs\n",
    "semantic_vis_events = np.array(semantic_vis_events)\n",
    "semantic_aud_events = np.array(semantic_aud_events)\n",
    "\n",
    "# Create epochs from -2 to +3 seconds relative to each trial onset within the block\n",
    "epochsVis = mne.Epochs(\n",
    "    raw_clean,\n",
    "    events=semantic_vis_events,\n",
    "    event_id={'even': int(event_dict['even']), 'odd': int(event_dict['odd'])},\n",
    "    tmin=-0.3,\n",
    "    tmax=1,\n",
    "    baseline=(None, 0)  # Adjust baseline as needed\n",
    ")\n",
    "epochAud = mne.Epochs(\n",
    "    raw_clean,\n",
    "    events=semantic_aud_events,\n",
    "    event_id={'even': int(event_dict['even']), 'odd': int(event_dict['odd'])},\n",
    "    tmin=-0.3,\n",
    "    tmax=1,\n",
    "    baseline=(None, 0)  # Adjust baseline as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 445 events and 667 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/p5w49zc93976_p2hxj1zws2w0000gn/T/ipykernel_89708/1647900075.py:7: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochCombined = mne.concatenate_epochs([epochsVis_balanced, epochAud_balanced])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 445 events and 667 original time points ...\n",
      "Not setting metadata\n",
      "890 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for LDA\n",
    "min_trials = min(len(epochsVis), len(epochAud))\n",
    "\n",
    "epochsVis_balanced = epochsVis[:min_trials]\n",
    "epochAud_balanced = epochAud[:min_trials]\n",
    "\n",
    "epochCombined = mne.concatenate_epochs([epochsVis_balanced, epochAud_balanced])\n",
    "labels = np.concatenate([np.ones(len(epochsVis_balanced)), 2 * np.ones(len(epochAud_balanced))]) # 1 for visual, 2 for auditory\n",
    "\n",
    "# Check size of epochCombined data\n",
    "ntrials, nchannels, ntimes = epochCombined.get_data().shape\n",
    "\n",
    "# Initialize accuracy array\n",
    "accuracy_timecourse = np.zeros((ntimes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m data_t \u001b[38;5;241m=\u001b[39m epochCombined\u001b[38;5;241m.\u001b[39mget_data()[:, :, t]\n\u001b[1;32m     13\u001b[0m fold_accuracies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((nkfolds, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mkf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_t\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     16\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m data_t[train_index], data_t[test_index]\n\u001b[1;32m     17\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m labels[train_index], labels[test_index]\n",
      "\u001b[0;31mTypeError\u001b[0m: split() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "nkfolds = 10\n",
    "kf = KFold(n_splits=nkfolds)\n",
    "# Loop through each time point\n",
    "for t in range(ntimes):\n",
    "    print(t/ntimes)\n",
    "    data_t = epochCombined.get_data()[:, :, t]\n",
    "\n",
    "    fold_accuracies = np.zeros((nkfolds, 1))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(data_t)):\n",
    "        X_train, X_test = data_t[train_index], data_t[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        # Perform LDA\n",
    "        mean_vis = np.mean(X_train[y_train == 1], axis=0)\n",
    "        mean_aud = np.mean(X_train[y_train == 2], axis=0)\n",
    "        # within class covariance\n",
    "        Sw = np.cov(X_train[y_train == 1]) + np.cov(X_train[y_train == 2])\n",
    "        # between class covariance\n",
    "        Sb = np.cov(mean_vis - mean_aud)\n",
    "\n",
    "        # Get the eigenvalues and eigenvectors\n",
    "        eigvals, eigvecs = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))\n",
    "        idx = eigvals.argsort()[::-1]\n",
    "        eigvecs = eigvecs[:, idx] # Sort eigenvectors based on eigenvalues\n",
    "\n",
    "        # Project the data onto the first eigenvector\n",
    "        test_proj = X_test.dot(eigvecs[:, 0])\n",
    "\n",
    "        # Compute mean of projected training data\n",
    "        mean_vis_proj = np.mean(X_train[y_train == 1].dot(eigvecs[:, 0]))\n",
    "        mean_aud_proj = np.mean(X_train[y_train == 2].dot(eigvecs[:, 0]))\n",
    "\n",
    "        # test if projected data is closer to mean_vis_proj or mean_aud_proj\n",
    "        predictions = np.zeros_like(test_proj)\n",
    "        for j in range(len(test_proj)):\n",
    "            if np.abs(test_proj[j] - mean_vis_proj) < np.abs(test_proj[j] - mean_aud_proj):\n",
    "                predictions[j] = 1\n",
    "            else:\n",
    "                predictions[j] = 2\n",
    "\n",
    "        # Compute accuracy\n",
    "        fold_accuracies[i] = np.mean(predictions == y_test)\n",
    "\n",
    "    accuracy_timecourse[t] = np.mean(fold_accuracies)\n",
    "\n",
    "print(f'Time taken: {time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegmeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
